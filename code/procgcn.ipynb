{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import TopKPooling, GraphConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_pyg.pkl','rb') as ftrain:\n",
    "  train_dataset=pickle.load(ftrain)\n",
    "with open('data/test_pyg.pkl','rb') as ftest:\n",
    "  test_dataset=pickle.load(ftest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, num_layers, hidden, ratio=0.8, dropout=0):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(num_features, hidden, aggr='mean')\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.pools = torch.nn.ModuleList()\n",
    "        self.convs.extend([\n",
    "            GraphConv(hidden, hidden, aggr='mean')\n",
    "            for i in range(num_layers - 1)\n",
    "        ])\n",
    "        self.lin1 = Linear(num_layers * hidden, hidden)\n",
    "        self.lin2 = Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x.to_dense(), data.edge_index, data.batch\n",
    "        edge_weight = None\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        xs = [global_mean_pool(x, batch)]\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "            x = F.relu(x)\n",
    "            xs += [global_mean_pool(x, batch)]\n",
    "            if i % 2 == 0 and i < len(self.convs) - 1:\n",
    "                pool = self.pools[i // 2]\n",
    "                x, edge_index, edge_weight, batch, _ = pool(\n",
    "                    x=x, edge_index=edge_index, edge_weight=edge_weight,\n",
    "                    batch=batch)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=Net(1443,2,4,64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    loss_all=0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1))\n",
    "        loss_all += data.y.size(0) * float(loss)\n",
    "        correct += int(pred.max(dim=1)[1].eq(data.y.view(-1)).sum())\n",
    "\n",
    "    return loss_all / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.032, Train Acc: 0.990, Test Loss: 0.408, Test Acc: 0.961\n",
      "Epoch: 002, Train Loss: 0.041, Train Acc: 0.988, Test Loss: 0.385, Test Acc: 0.965\n",
      "Epoch: 003, Train Loss: 0.035, Train Acc: 0.985, Test Loss: 0.420, Test Acc: 0.960\n",
      "Epoch: 004, Train Loss: 0.045, Train Acc: 0.991, Test Loss: 0.382, Test Acc: 0.966\n",
      "Epoch: 005, Train Loss: 0.029, Train Acc: 0.991, Test Loss: 0.395, Test Acc: 0.968\n",
      "Epoch: 006, Train Loss: 0.028, Train Acc: 0.991, Test Loss: 0.418, Test Acc: 0.968\n",
      "Epoch: 007, Train Loss: 0.037, Train Acc: 0.989, Test Loss: 0.428, Test Acc: 0.965\n",
      "Epoch: 008, Train Loss: 0.031, Train Acc: 0.991, Test Loss: 0.446, Test Acc: 0.968\n",
      "Epoch: 009, Train Loss: 0.028, Train Acc: 0.991, Test Loss: 0.436, Test Acc: 0.966\n",
      "Epoch: 010, Train Loss: 0.029, Train Acc: 0.991, Test Loss: 0.445, Test Acc: 0.965\n",
      "Epoch: 011, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.463, Test Acc: 0.963\n",
      "Epoch: 012, Train Loss: 0.036, Train Acc: 0.991, Test Loss: 0.443, Test Acc: 0.965\n",
      "Epoch: 013, Train Loss: 0.048, Train Acc: 0.982, Test Loss: 0.545, Test Acc: 0.951\n",
      "Epoch: 014, Train Loss: 0.037, Train Acc: 0.991, Test Loss: 0.326, Test Acc: 0.966\n",
      "Epoch: 015, Train Loss: 0.036, Train Acc: 0.989, Test Loss: 0.493, Test Acc: 0.958\n",
      "Epoch: 016, Train Loss: 0.034, Train Acc: 0.992, Test Loss: 0.357, Test Acc: 0.962\n",
      "Epoch: 017, Train Loss: 0.026, Train Acc: 0.992, Test Loss: 0.374, Test Acc: 0.968\n",
      "Epoch: 018, Train Loss: 0.028, Train Acc: 0.991, Test Loss: 0.381, Test Acc: 0.966\n",
      "Epoch: 019, Train Loss: 0.030, Train Acc: 0.991, Test Loss: 0.366, Test Acc: 0.967\n",
      "Epoch: 020, Train Loss: 0.027, Train Acc: 0.991, Test Loss: 0.392, Test Acc: 0.963\n",
      "Epoch: 021, Train Loss: 0.029, Train Acc: 0.992, Test Loss: 0.390, Test Acc: 0.962\n",
      "Epoch: 022, Train Loss: 0.025, Train Acc: 0.992, Test Loss: 0.407, Test Acc: 0.962\n",
      "Epoch: 023, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.428, Test Acc: 0.962\n",
      "Epoch: 024, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.387, Test Acc: 0.962\n",
      "Epoch: 025, Train Loss: 0.026, Train Acc: 0.991, Test Loss: 0.450, Test Acc: 0.961\n",
      "Epoch: 026, Train Loss: 0.034, Train Acc: 0.990, Test Loss: 0.394, Test Acc: 0.962\n",
      "Epoch: 027, Train Loss: 0.029, Train Acc: 0.992, Test Loss: 0.457, Test Acc: 0.958\n",
      "Epoch: 028, Train Loss: 0.036, Train Acc: 0.992, Test Loss: 0.379, Test Acc: 0.967\n",
      "Epoch: 029, Train Loss: 0.028, Train Acc: 0.992, Test Loss: 0.397, Test Acc: 0.963\n",
      "Epoch: 030, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.411, Test Acc: 0.962\n",
      "Epoch: 031, Train Loss: 0.025, Train Acc: 0.992, Test Loss: 0.413, Test Acc: 0.962\n",
      "Epoch: 032, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.388, Test Acc: 0.967\n",
      "Epoch: 033, Train Loss: 0.032, Train Acc: 0.985, Test Loss: 0.386, Test Acc: 0.962\n",
      "Epoch: 034, Train Loss: 0.031, Train Acc: 0.992, Test Loss: 0.438, Test Acc: 0.961\n",
      "Epoch: 035, Train Loss: 0.029, Train Acc: 0.979, Test Loss: 0.433, Test Acc: 0.962\n",
      "Epoch: 036, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.473, Test Acc: 0.958\n",
      "Epoch: 037, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.498, Test Acc: 0.961\n",
      "Epoch: 038, Train Loss: 0.037, Train Acc: 0.991, Test Loss: 0.403, Test Acc: 0.967\n",
      "Epoch: 039, Train Loss: 0.025, Train Acc: 0.991, Test Loss: 0.435, Test Acc: 0.963\n",
      "Epoch: 040, Train Loss: 0.026, Train Acc: 0.992, Test Loss: 0.451, Test Acc: 0.966\n",
      "Epoch: 041, Train Loss: 0.031, Train Acc: 0.991, Test Loss: 0.455, Test Acc: 0.962\n",
      "Epoch: 042, Train Loss: 0.023, Train Acc: 0.992, Test Loss: 0.454, Test Acc: 0.965\n",
      "Epoch: 043, Train Loss: 0.027, Train Acc: 0.992, Test Loss: 0.468, Test Acc: 0.963\n",
      "The Best Epoch: 014,Test Loss: 0.430, Test Acc: 0.962\n"
     ]
    }
   ],
   "source": [
    "best_test_acc = test_acc = 0\n",
    "best_test_loss = float('inf')\n",
    "patience = start_patience = 30\n",
    "for epoch in range(1, 1000):\n",
    "    train_loss = train(epoch)\n",
    "    _, train_acc = test(train_loader)\n",
    "    test_loss, test_acc = test(test_loader)\n",
    "    if test_loss < best_test_loss:        \n",
    "        best_test_loss=test_loss\n",
    "        best_test_acc = test_acc\n",
    "        patience = start_patience\n",
    "        best_epoch =  epoch\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            break\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}, '\n",
    "          f'Train Acc: {train_acc:.3f}, '\n",
    "          f'Test Loss: {test_loss:.3f}, '\n",
    "          f'Test Acc: {test_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Epoch: 014,Test Loss: 0.326, Test Acc: 0.966\n"
     ]
    }
   ],
   "source": [
    "print(f'The Best Epoch: {best_epoch:03d},Test Loss: {best_test_loss:.3f}, Test Acc: {best_test_acc:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
